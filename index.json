[{"categories":["Machine Learning"],"contents":"在學習了眾多機器學習、資料分析等方法後不禁思考:下一步呢? 該如何讓建立的模型或分析的成果能實際落地提供使用?\n本篇以天池競賽中的製造業數據為例，創建機器學習系統，包含模型建置、API服務部署及系統監控，並結合CICD將流程自動化。\nData source 本數據集是關於化工連續製程的數據，目標是希望預測Yield，屬於迴歸問題(regression)，本案例中模擬從AWS S3取得資料\nDigital Manufacturing Algorithm Competition of JinNan Tianjin\nModel Deployment 要建立一個機器學習系統，ML code可能只佔相當小的一部份，大多數會是在處理處理資料蒐集、特徵工程、部署、系統監控等等 Source:Hidden Technical Debt in Machine Learning Systems(2015)\n以機器學習建模來說，一般會經過Data validation-\u0026gt;Feature engineering-\u0026gt;Model training-\u0026gt;Model deployment。機器學習系統比起傳統IT系統多了Data+Model，以致較難以明確規範系統行為；其中要注意的是\u0026rdquo;Reproducibility\u0026rdquo;, 意思是在上述各個流程模組中，必須確保當給定一樣的Input就應該得到一樣的Output，這是ML系統所面臨的重要挑戰；另外也是必須針對系統撰寫測試(Testing)的重要原因，期望能降低系統發生非預期行為(Uncertainty)的風險。\n那該如何確保\u0026rdquo;Reproducibility\u0026rdquo;? 基本有三個方向\n 版本控制 (Version Control) 盡可能設置Seed (if require randomness) 使用容器 (Container)  End-to-end ML system 下圖為建構端到端ML系統的流程，並且可能會不斷地迭代。 Source: Continuous Delivery for Machine Learning end-to-end process\n下圖是在學習機器學習部署的過程所歸納整理，本案例也參考這樣的設計來構建系統 以下針對幾點說明\nProductionize Model 其實我們要部署的並非只有模型本身，而是整個從資料處理到建模部署的pipeline。在這部分會將特徵工程、建模等一系列步驟透過sklearn.pipeline進行封裝，將訓練完的模型(.pkl)給予版本並將前處理、模型訓練、設定檔等打包成package並推送至Python package index server,常見的有公開的PyPI,而此處是使用gemfury,為的是能夠建立不公開的Package Repository\nDeployment(Sering the model via API) 在部署的部分，此處採用Python 3.6+之支援異步高效能框架FastAPI，好處是可以自動生成openAPI sepc並且可以簡單的直接使用Pydantic進行Schema Validation。\nSource: tiangolo/fastapi\n下圖是本例的API docs 在應用的部署上會透過Docker將服務容器化，由於需要運作多個服務(MLAPI, Prometheus, Grafana, cAdvisor)，此處會透過docker-compose一次啟動\nWhy docker for ML?  重現性(Reproducibility): 以確保每次運行結果一致 可擴展性(Scalibility): 各大雲端皆支援，易於整合 隔離性(Isolation): 確保服務獨立運作且資源隔離(Process Isolation) 維護性(Maintainability): 環境易設定且可攜帶使團隊間容易分享 Source: SUPERCHARGE YOUR DEVELOPMENT ENVIRONMENT (USING DOCKER)  Deploy to Cloud 可以將應用部署上雲端以提供服務，可以選擇是PaaS或是IaaS，此處各選擇Heroku 以及 AWS 來部署，PaaS 或是 IaaS的差異如下圖，選擇IaaS的話有較多部份需要自己管理，但也相對較為彈性。 Source: RedHat\n此處以AWS部署為例，使用到的服務有\n  Elastic Container Registry(ECR): 將打包好的image上傳到此存放，供其他AWS服務存取   Amazon Elastic Container Service(ECS):AWS上管理Dokcer container的服務，下圖為ECS的架構，需先創建一個Cluster在定義內部的Service與Task\nSource: AWS\n  下圖為本案例實作時所創建的Cluster，並且創建了一個名為custom-service的服務 Monitoring 透過Prometheus與Grafana的搭配來搭建監控儀表板。下圖為Prometheus架構，透過HTTP的PULL方式週期性抓取並儲存時間序列資料，只要提供對應的HTTP介面並且符合 Promethues 定義的格式即可監控；且有提供PromQL語言進行查詢再透過Grafana進行資料可視化，當異常發生時也可以設置alert警報。\nSource: Prometheus\n本案例在監控的部分主要分三個部分:\n Docker Monitoring: 用於監控Docker系統資源，使用工具:google/cAdvisor Source: 8bitmen.com  下圖為案例示範，主要針對四個服務的CPU跟記憶體進行監控 Model Monitoring: 可以針對模型的預測值進行監控  每單位時間有多少預測值，是否發生異常 監控模型的預測值在不同時間點是否發生顯著變化(可搭配Z-score/SEM/STD等統計資訊)   Log  可以用ELK Stack進行    如果有text類型資料，Kibana相對Grafana適合，時間序列DB可能因high cardinality造成performance的問題\nContinuous Integration/Continuous Deployment(CI/CD) 主要是希望能將應用開發測試與部署的每個階段自動化，可讓系統是在一個\u0026quot;always releasable\u0026quot;的狀態，且整個過程標準化、透明化並易於追蹤。CI/CD的工具相當多，此處使用的工具是CircleCI Source:CircleCI\n首先須撰寫設定檔config.yml，透過定義各種job跟steps來定義流程中的每個步驟，包含所需的環境或設定，所要執行的指令等等。CircleCI可以方便地與github專案連動，當新開一個Pull request，或後續該分支的commit時，就會觸發jobs。\n下圖為本案範例，當test_app(mlapi的單元測試與整合測試)通過後，才進行應用的部署，並且只有在merger到main並給予該commit tag後才進行model package的上傳發佈。\n下圖以\u0026quot;test_app\u0026quot;這個job為例，其中tox是一款python自動化測試工具，可以整合pytest一起使用。 Additional Resources  Deployment of Machine Learning Models - Online Course Testing and Monitoring Machine Learning Model Deployments - Online Course  ","permalink":"https://bruceewue.github.io/blog/ml_deployment/","tags":["MLOps","Python"],"title":"ML Model Deployment"},{"categories":["Data"],"contents":"自己來動手製作的COVID-19 Dashboard吧，本篇將透過GCP雲端服務自動抓取最新的疫情資料，並使用Google的可視化工具Data studio串接來製作每日自動更新的疫情儀表板。\nData source CSSEGISandData/COVID-19\nDiagram 透過Cloud Scheduler定時觸發Cloud Functions中部署的爬蟲程式,並將資料儲存至Cloud Storage，並由Data Studio即時讀取最新資料並製作COVID-19即時資訊儀表板。\nGCP Source: Google\n這次採用的雲端平台GCP內含相當多的服務可以使用，目前有提供300美金3個月的免費額度可使用；而本篇使用到的服務主要有Cloud Storage, Cloud Functions, Cloud Scheduler\nCloud Functions 利用Cloud Functions來新增一個可透過Http request觸發的爬蟲程式，記得在requirements.txt 寫入需安裝的套件(此處為pandas以及google-cloud-storage)，\n爬取確診人數的部分如下，也可以新增迴圈連同死亡、復原的人數一起抓取。\nimport pandas as pd def crawler(request): # get data from github df = pd.read_csv(\u0026#34;https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\u0026#34;) # wide format to long format df = pd.melt(df, id_vars=df.columns[:4], value_vars=df.columns[4:], var_name=\u0026#34;date\u0026#34;, value_name=\u0026#34;count\u0026#34;) return df.to_csv(index=False) 由於需要抓取自動後上傳至Cloud Storage，所以還需加入以下網址內程式碼 Uploading objects\nNote:\n Cloud Functions只允許在 /tmp路徑下才能存檔。 Cloud functions 與 Cloud Storage建議在同個地區，避免額外傳輸費用。  Cloud Storage 雲端儲存空間，新增bucket後即可開始使用，也能像google drive一樣手動上傳檔案，但Cloud Storage的優勢是更能方便地在GCP上與各服務串接；免費的部分有5GB的額度。\n觸發Cloud functions後可以確認看看是否有確實上傳確診、死亡、復原的資料 Note:\n Cloud functions 與 Cloud Storage建議在同個地區，避免額外傳輸費用。  Cloud Scheduler 可以依據原始資料的更新時間來設定希望多久執行一次爬蟲，設定方式是像在Linux中的Crontab排程，使用Cron語法，可以利用這個網站確認自己撰寫的排程是否符合預期。\n設定完成的狀態如下 Note:\n Cloud Scheduler完全免費方案只有設定3個Job的額度  Data Studio 在設定好資料後就可以嘗試來把它視覺化了，這裡採用的是google免費的Data Studio，算是滿容易上手的工具，跟GCP串接當然也是沒有問題的。\n此處新增資料源-\u0026gt;從Data Storage內選取三份csv檔案\nResult COVID-19 Dashboard Animated Bar Chart  即時資訊互動儀表板如下，可自由選擇Country/Region (建議可點擊右下角\u0026quot;Google數據分析\u0026quot;觀看完整報表)  \r.iframe-container { position: relative;\rwidth: 100%;\rheight: 0;\rpadding-bottom: 56%; } .iframe-container iframe { position: absolute;\rwidth: 100%;\rheight: 100%;\rleft: 0;\rtop: 0;\r}\r\r\r\rAdditional Resources  打造動態報表！雲端 Python 爬蟲資料流  ","permalink":"https://bruceewue.github.io/blog/covid_dashboard/","tags":["Data studio","Dashboard","GCP","Python"],"title":"Create COVID-19 Dashboard by Data studio"},{"categories":["Others"],"contents":"Markdown Example\nHeading 1 Heading 2 Heading 3 Heading 4 Heading 5 Heading 6 Emphasis Emphasis, aka italics, with asterisks or underscores.\nStrong emphasis, aka bold, with asterisks or underscores.\nCombined emphasis with asterisks and underscores.\nStrikethrough uses two tildes. Scratch this.\nLink I\u0026rsquo;m an inline-style link\nI\u0026rsquo;m an inline-style link with title\nI\u0026rsquo;m a reference-style link\nYou can use numbers for reference-style link definitions\nOr leave it empty and use the link text itself.\nURLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example).\nSome text to show that the reference links can follow later.\n  Steve Francia test\n  List  有序1  四個空格內縮   有序2 有序3  Unordered List  無序1  四個空格內縮   無序2  Blockquote  This is a blockquote example.\n Inline code has back-ticks around it.\nvar s = \u0026#34;JavaScript syntax highlighting\u0026#34;; alert(s); print(\u0026#34;hello Bruce\u0026#34;) print(\u0026#34;hello Bruce\u0026#34;) print(\u0026#34;hello Bruce\u0026#34;) No language indicated, so no syntax highlighting. But let's throw in a \u0026lt;b\u0026gt;tag\u0026lt;/b\u0026gt;.\rInline HTML You can also use raw HTML in your Markdown, and it\u0026rsquo;ll mostly work pretty well.\nTables Colons can be used to align columns.\n   Tables Are Cool     col 3 is right-aligned $1600   col 2 is centered $12   zebra stripes are neat $1    There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u0026rsquo;t need to make the raw Markdown line up prettily. You can also use inline Markdown.\n   Markdown Less Pretty     Still renders nicely   1 2 3    Youtube embeded   ","permalink":"https://bruceewue.github.io/blog/markdown_test/","tags":["Hugo","Markdown"],"title":"Markdown test"}]